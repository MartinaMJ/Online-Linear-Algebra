{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19dda670",
   "metadata": {},
   "source": [
    "# Metrics, Distances, and Norms\n",
    "\n",
    "In addition to manipulating elements of linear vector spaces using\n",
    "linear transformations, we may also define and calculate *distances*\n",
    "between elements of the space. Although a quite familiar concept,\n",
    "distances can be defined in different ways and with different purposes,\n",
    "therefore requiring a formal definition. Looking at a map of the city,\n",
    "we can measure distances between points of interest and even order them\n",
    "based on their distances to a reference point. However, if we are\n",
    "driving and need to follow the roads of the city, the distance measured\n",
    "with the map may be different from the distance traveled on the streets.\n",
    "And yet the concept of shorter and longer distances shall still make\n",
    "sense.\n",
    "\n",
    "Given a set $\\mathcal{U}$, we define a *metric* as a nonnegative\n",
    "function\n",
    "$f(\\mathbf{u},\\mathbf{v}):\\mathcal{U}\\times\\mathcal{U}\\rightarrow\\mathbb{R}$\n",
    "satisfying the following properties:\n",
    "\n",
    "-   $f(\\mathbf{u},\\mathbf{v})=f(\\mathbf{v},\\mathbf{u})$.\n",
    "\n",
    "-   $f(\\mathbf{u},\\mathbf{v})=0$ if, and only if,\n",
    "    $\\mathbf{u}=\\mathbf{v}$.\n",
    "\n",
    "-   $f(\\mathbf{u},\\mathbf{v})+f(\\mathbf{v},\\mathbf{w})\\ge f(\\mathbf{u},\\mathbf{w})$.\n",
    "\n",
    "The last property is often called the *triangle inequality*.\n",
    "\n",
    "Given a vector space $\\mathcal{U}$, we may wish to measure the distance\n",
    "between any two vectors, $\\mathbf{u}$ and $\\mathbf{v}$, $n$-tuples which\n",
    "are elements of $\\mathcal{U}$. For this purpose, we define a particular\n",
    "metric, called a *vector norm* in $\\mathcal{U}$, herein often called\n",
    "simply a *norm*, and denoted as\n",
    "$\\|\\cdot\\|:\\mathcal{U}\\rightarrow\\mathbb{R}$. For\n",
    "$\\mathbf{u},\\ \\mathbf{v}\\in\\mathcal{U}$, $\\|\\mathbf{u}-\\mathbf{v}\\|$\n",
    "denotes some distance from $\\mathbf{u}$ to $\\mathbf{v}$;\n",
    "$\\|\\mathbf{u}\\|$ denotes some distance from $\\mathbf{u}$ to the origin.\n",
    "\n",
    "Norms are also nonnegative functions that must satisfy the properties\n",
    "outlined above, i.e.,\n",
    "\n",
    "-   $\\|\\mathbf{u}-\\mathbf{v}\\|=\\|\\mathbf{v}-\\mathbf{u}\\|$.\n",
    "\n",
    "-   $\\|\\mathbf{u}-\\mathbf{v}\\|=0$ if, and only if,\n",
    "    $\\mathbf{u}=\\mathbf{v}$.\n",
    "\n",
    "-   $\\|\\mathbf{u}-\\mathbf{v}\\|+\\|\\mathbf{v}-\\mathbf{w}\\|\\ge\\|\\mathbf{u}-\\mathbf{w}\\|$.\n",
    "\n",
    "In addition, norms must satisfy the *absolute homogeneity* property,\n",
    "$$\\|\\alpha(\\mathbf{u}-\\mathbf{v})\\|=|\\alpha|\\|\\mathbf{u}-\\mathbf{v}\\|$$\n",
    "where $|\\alpha|$ denotes de absolute value of the scalar $\\alpha$.\n",
    "\n",
    "The $p$-norm, often denoted as the $l_p$ norm, is a function which is a\n",
    "norm and is of particular interest to us:\n",
    "$$\\|\\mathbf{u}-\\mathbf{v}\\|_p=\\left(\\sum_{i=1}^n|u_i-v_i|^p\\right)^{1/p},\\quad p\\ge 1$$\n",
    "When $p=1$ in the definition of norm above, the measured distance is the\n",
    "sum of the absolute values of the vector elements. This norm is often\n",
    "referred to as the $l_1$ norm, the *taxicab norm* or the *Manhattan\n",
    "norm*, for it gives the distance as if following the streets of a city:\n",
    "$$\n",
    "\\|\\mathbf{u}\\|_1 = \\sum_{i=1}^n |u_i|\n",
    "$$\n",
    "On the other hand, for \\( p=2 \\), the norm is often called the \\( l_2 \\) norm, or the *Euclidean norm*, and yields its length:\n",
    "$$\n",
    "\\|\\mathbf{u}\\|_2 = \\sqrt{\\sum_{i=1}^n |u_i|^2}\n",
    "$$\n",
    "If we take \\( p \\) to the limit where $p \\to \\infty$, then the \\( p \\)-norm becomes the $\\infty$ norm, or the *max norm*:\n",
    "$$\n",
    "\\|\\mathbf{u}\\|_\\infty = \\max_i \\{ |u_i| \\}\n",
    "$$\n",
    "\n",
    "Figure <a href=\"#fig:p-norm\" data-reference-type=\"ref\"\n",
    "data-reference=\"fig:p-norm\">1</a> shows an example of the $p$-norm of a\n",
    "vector $\\mathbf{v}\\in\\mathbb{R}^2$ for different values of $p$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3af42805",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'graph.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpimg\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(\u001b[43mmpimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgraph.jpg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39maxis(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moff\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\image.py:1541\u001b[0m, in \u001b[0;36mimread\u001b[1;34m(fname, format)\u001b[0m\n\u001b[0;32m   1534\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fname, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(parse\u001b[38;5;241m.\u001b[39murlparse(fname)\u001b[38;5;241m.\u001b[39mscheme) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1535\u001b[0m     \u001b[38;5;66;03m# Pillow doesn't handle URLs directly.\u001b[39;00m\n\u001b[0;32m   1536\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1537\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease open the URL for reading and pass the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1538\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult to Pillow, e.g. with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m``np.array(PIL.Image.open(urllib.request.urlopen(url)))``.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1540\u001b[0m         )\n\u001b[1;32m-> 1541\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mimg_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m image:\n\u001b[0;32m   1542\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (_pil_png_to_float_array(image)\n\u001b[0;32m   1543\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(image, PIL\u001b[38;5;241m.\u001b[39mPngImagePlugin\u001b[38;5;241m.\u001b[39mPngImageFile) \u001b[38;5;28;01melse\u001b[39;00m\n\u001b[0;32m   1544\u001b[0m             pil_to_array(image))\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\PIL\\Image.py:3131\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   3128\u001b[0m     filename \u001b[38;5;241m=\u001b[39m fp\n\u001b[0;32m   3130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename:\n\u001b[1;32m-> 3131\u001b[0m     fp \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3132\u001b[0m     exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   3134\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'graph.jpg'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "plt.imshow(mpimg.imread('graph.jpg'))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4fa99af",
   "metadata": {},
   "source": [
    "Given the definition of norm in a linear vector space, we can say that\n",
    "all vectors have positive norm, except the null vector, which has norm\n",
    "equal to zero. For a given norm, we say that the vector is *normalized*\n",
    "if its norm is equal to one. Likewise, vector normalization implies\n",
    "multiplication by the inverse of the norm. It is often the case that we\n",
    "refer to the Euclidean norm for normalization, i.e., if not stated\n",
    "explicitly otherwise, a normalized vector has its Euclidean norm equal\n",
    "to one.\n",
    "\n",
    "<span id=\"def:equiv_norms\" label=\"def:equiv_norms\"></span> Two vector\n",
    "norms $\\|\\cdot\\|_\\alpha$ and $\\|\\cdot\\|_\\beta$ in a vector space\n",
    "$\\mathcal{U}$ are *equivalent* if, and only if, there are scalars\n",
    "$c_1>0$ and $c_2>0$ such that\n",
    "$$c_1 \\|\\mathbf{u}\\|_\\alpha \\le \\|\\mathbf{u}\\|_\\beta \\le c_2 \\|\\mathbf{u}\\|_\\alpha, \\quad \\forall \\mathbf{u} \\in \\mathcal{U}$$\n",
    "\n",
    "The condition, which is only sufficient for metrics, becomes necessary and sufficient when the metric is derived from a norm.\n",
    "\n",
    "Based on the definition above, we can state the following theorem, which\n",
    "relates to equivalent norms in finite dimensional vector spaces.\n",
    "\n",
    "<span id=\"theo:equiv_norms\" label=\"theo:equiv_norms\"></span> Let\n",
    "$\\mathcal{U}$ be a finite dimensional vector space defined over\n",
    "$\\mathbb{R}$ or $\\mathbb{C}$. All norms defined in $\\mathcal{U}$ are\n",
    "equivalent.\n",
    "\n",
    "*Proof.* Let $\\|\\cdot\\|_\\beta$ be any norm in $\\mathcal{U}$ and let the set {$\\mathbf{v}_i$} be a basis of $\\mathcal{U}$, with  $\\text{dim}(\\mathcal{U})$ = n. Any vector $\\mathbf{u} \\in \\mathcal{U}$ can be written as\n",
    "\n",
    "$$\n",
    "\\mathbf{u} = \\sum_{i=1}^n a_i \\mathbf{v}_i\n",
    "$$\n",
    "\n",
    "Let $\\|\\cdot\\|_\\alpha$ denote another norm in $\\mathcal{U}$, defined as\n",
    "\n",
    "$$\n",
    "\\|\\mathbf{u}\\|_\\alpha = \\sum_{i=1}^n |a_i|\n",
    "$$\n",
    "\n",
    "We will show that for any norm $\\|\\cdot\\|_\\beta$, the two norms are equivalent in $\\mathcal{U}$, therefore all norms in $\\mathcal{U}$ are equivalent.\n",
    "\n",
    "$$\n",
    "\\|\\mathbf{u}\\|_\\beta = \\left\\|\\sum_{i=1}^n a_i \\mathbf{v}_i \\right\\|_\\beta\n",
    "\\leq \\sum_{i=1}^n |a_i| \\|\\mathbf{v}_i\\|_\\beta\n",
    "\\leq c_2 \\sum_{i=1}^n |a_i| = c_2 \\|\\mathbf{u}\\|_\\alpha\n",
    "$$\n",
    "\n",
    "for $c_2 = \\max_i \\|\\mathbf{v}_i\\|_\\beta$.\n",
    "Now for the lower limit, let\n",
    "$\\mathcal{S}=\\{\\mathbf{u}\\in\\mathbb{R}^n:\\|\\mathbf{u}\\|_\\alpha=1\\}$ be\n",
    "the unit sphere for the norm $\\|\\cdot\\|_\\alpha$ in $\\mathbb{R}^n$. As\n",
    "$\\mathcal{S}$ is continuous, bounded, and closed,\n",
    "$\\min_{\\mathbf{u}\\in\\mathcal{S}}\\|\\mathbf{u}\\|_\\beta$ is achievable for\n",
    "some $\\mathbf{u}\\in\\mathcal{S}$. For any vector\n",
    "$\\mathbf{u}\\in\\mathcal{U}$, we have $$\\begin{split}\n",
    "    \\|\\mathbf{u}\\|_\\beta\n",
    "    &=\\|\\sum_{i=1}^n a_i\\mathbf{v}_i\\|_\\beta\n",
    "    =\\frac{\\sum_{i=1}^n|a_i|}{\\sum_{i=1}^n|a_i|}\\|\\sum_{i=1}^n a_i\\mathbf{v}_i\\|_\\beta\n",
    "    =\\|\\sum_{i=1}^n \\frac{a_i}{\\sum_{i=1}^n|a_i|}\\mathbf{v}_i\\|_\\beta\\sum_{i=1}^n|a_i|\\\\\n",
    "    &\\ge c_1\\sum_{i=1}^n|a_i|\n",
    "    =c_1\\|\\mathbf{u}\\|_\\alpha\n",
    "\\end{split}$$ for\n",
    "$c_1=\\min_{\\mathbf{u}\\in\\mathcal{S}}\\|\\mathbf{u}\\|_\\beta$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3449e375",
   "metadata": {},
   "source": [
    "### Example of metrics\n",
    "\n",
    "A very widespread use of norms and metrics is the KNN (K-nearest neighbors) machine learning algorithm. This is one of the oldest machine learning algorithms, being published for the first time in 1951. Simply, this method seeks to classify a certain event based on the classification of its k-nearest neighbors, where k is a natural number. \n",
    "\n",
    "The main goal of any classifying machine learning algorithm is to put data into categories based on its other characteristics. Simply, KNN does this by mapping out unclassified data with classified data, calculating what are the unclassified data's k-nearest neighbors with a specific metric, and, finally classifiying the unclassified data according to the majority class among the k-nearest neighbors. \n",
    "\n",
    "One of the most famous datasets used for understanding KNN is the Iris dataset, which was constructed by British biologist Ronald Fisher in 1936. This dataset has 50 samples of data that represent three flowers from the genus Iris: *Iris setosa*, *Iris virginica* and *Iris versicolor*. Each sample is has four variables: length of petals, width of petals, length of sepals and width of sepals. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a9747f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import numpy as np\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "fig, (sep, pet) = plt.subplots(2)\n",
    "scatter1 = sep.scatter(iris.data[:, 0], iris.data[:, 1], s=7, c=iris.target)\n",
    "sep.set(xlabel=iris.feature_names[0], ylabel=iris.feature_names[1])\n",
    "scatter2 = pet.scatter(iris.data[:, 2], iris.data[:, 3], s=7, c=iris.target)\n",
    "pet.set(xlabel=iris.feature_names[2], ylabel=iris.feature_names[3])\n",
    "fig = pet.legend(scatter2.legend_elements()[0], iris.target_names, loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154d2963",
   "metadata": {},
   "source": [
    "The first plot above is sepal width x sepal length, and the second plot above is petal width x petal length. Essentially, the KNN algorithm maps unclassfied data in the 4 dimensional vector space, with each degree of freedom being one variable, and measures the metric between the unclassified data and each sample of classfied data. Typically, the euclidian metric is used. The K smallest metrics calculated represent the \"K-nearest neighbors\". The unclassified data is then classified to the class which contains the majority of the neighbors.\n",
    "\n",
    "As it is possible to see, this method is very simple, and is very useful in specific applications. Unlike many machine learning algorithms, KNN does not need \"training\", which mean that it does not need to observe a complete classified dataset in order to observe standards, and therefore create a mathematical model. A significant disadvantage of KNN is called \"curse of dimensionality\". When there are too many variables, the neighbors tend to be distant, which makes correct classifications difficult. Also, with larger datasets, this algorithm requires many computational resources, since it has to calculate the distance between the unclassified data and all of the samples in the data set. This limitation makes it best for smaller datasets, which can lead to another problem: overfitting. This occurs when a machine learning model is too close to the dataset it has been trained with, making it inadequate for unclassified data with variables distant from those of the dataset.\n",
    "\n",
    "In order to see this for yourself, modify the values of each variable in order to create a sample of an Iris flower. The model will tell you what species it likely belongs to. Modify the value of k to obtain different results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a43410",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "\n",
    "sepal_length = 7.3\n",
    "sepal_width = 3\n",
    "petal_length = 5.5\n",
    "petal_width = 7\n",
    "\n",
    "flower = np.array([[sepal_length, sepal_width, petal_length, petal_width]])\n",
    "k = 3\n",
    "\n",
    "knn = KNeighborsClassifier(k)\n",
    "\n",
    "knn.fit(iris.data, iris.target)\n",
    "\n",
    "result = knn.predict(flower)\n",
    "\n",
    "if result == [0]:\n",
    "    plt.imshow(mpimg.imread('Irissetosa1.jpg'))\n",
    "    plt.title(\"Iris setosa\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "elif result == [1]:\n",
    "    plt.imshow(mpimg.imread('Irisversicolor.jpg'))\n",
    "    plt.title(\"Iris versicolor\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "else:\n",
    "    plt.imshow(mpimg.imread('Irisvirginica.jpg'))\n",
    "    plt.title(\"Iris virginica\")\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
